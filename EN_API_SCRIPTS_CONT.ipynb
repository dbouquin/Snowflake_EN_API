{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "2c22676b-28bb-46a9-a3c3-42653dc0bd7a",
   "metadata": {
    "language": "sql",
    "name": "current_role",
    "resultHeight": 112
   },
   "outputs": [],
   "source": "SELECT CURRENT_ROLE()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c8d9dbd2-77d4-4cd0-923d-52cbc7783889",
   "metadata": {
    "language": "sql",
    "name": "get_EN_secret_UDF",
    "codeCollapsed": false,
    "resultHeight": 112
   },
   "outputs": [],
   "source": "CREATE OR REPLACE FUNCTION get_EN_secret()\nRETURNS STRING\nLANGUAGE PYTHON\nRUNTIME_VERSION = 3.11\nHANDLER = 'get_EN_secret'\nEXTERNAL_ACCESS_INTEGRATIONS = (EN_INTEGRATION)\nSECRETS = ('cred' = EN_API_DB_20241007)\nAS\n$$\nimport _snowflake\n\ndef get_EN_secret():   \n  my_api_key = _snowflake.get_generic_secret_string('cred') \n  return my_api_key\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46908a4d-3942-440f-99d7-8e58ffa387b5",
   "metadata": {
    "language": "python",
    "name": "execute_get_EN_secret_UDF",
    "codeCollapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nsession = get_active_session()\nresults = session.sql('SELECT get_EN_secret()').collect()\nEN_secret = results[0][0]\n#EN_secret # successfully returns secret string",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf51f870-3679-40ac-904c-8e60f49e7c81",
   "metadata": {
    "language": "python",
    "name": "full_script",
    "codeCollapsed": false,
    "resultHeight": 447
   },
   "outputs": [],
   "source": "# Import required packages\nfrom snowflake.snowpark.context import get_active_session\nimport pandas as pd\nimport requests\nimport os\nimport re\nfrom datetime import datetime, timezone\nimport logging\nimport tempfile\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef validate_email(email):\n    \"\"\"Validate email format\"\"\"\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return bool(re.match(pattern, email))\n\ndef get_api_token(session):\n    \"\"\"Retrieve API token from Snowflake using UDF\"\"\"\n    try:\n        results = session.sql('SELECT get_EN_secret()').collect()\n        return results[0][0]\n    except Exception as e:\n        logger.error(f\"Error retrieving API token: {str(e)}\")\n        raise\n\ndef get_most_recent_file(session):\n    \"\"\"Get the most recent CSV file from the stage\"\"\"\n    try:\n        file_query = \"LIST @CLASSYDATA.EN_API.NEW_FILES\"\n        list_files = session.sql(file_query).collect()\n        most_recent = max([f for f in list_files if f['name'].endswith('.csv')], \n                         key=lambda x: x['last_modified'])\n        return most_recent['name']\n    except Exception as e:\n        logger.error(f\"Error getting most recent file: {str(e)}\")\n        raise\n\ndef read_and_validate_data(session, file_path):\n    \"\"\"Read CSV file and validate email addresses\"\"\"\n    try:\n        # Read file into Snowpark DataFrame\n        snowpark_df = session.read.options({\"field_delimiter\": \",\", \"skip_header\": 1}).csv(f\"@CLASSYDATA.EN_API.{file_path}\")\n        snowpark_df = snowpark_df.toDF(\"EMAIL_ADDRESS\", \"CLASSY_WALK_2024\")\n        \n        # Convert to pandas and ensure no index\n        df = snowpark_df.to_pandas().reset_index(drop=True)\n        \n        # Debug output\n        print(\"\\n=== Initial DataFrame ===\")\n        print(df.head())\n        print(\"Columns:\", df.columns.tolist())\n        \n        # Validate emails\n        invalid_emails = [email for email in df['EMAIL_ADDRESS'] if not validate_email(email)]\n        if invalid_emails:\n            raise ValueError(f\"Invalid email formats found: {invalid_emails}\")\n        \n        return df\n    except Exception as e:\n        logger.error(f\"Error reading/validating data: {str(e)}\")\n        raise\n\ndef process_through_api(api_token, df, file_name):\n    \"\"\"Process data through Engaging Networks API\"\"\"\n    try:\n        # Get just the base filename without directory path\n        base_file_name = os.path.basename(file_name)\n        print(f\"Using filename: {base_file_name}\")\n        \n        # Debug: Show DataFrame before CSV creation\n        print(\"\\n=== DataFrame Before CSV Creation ===\")\n        print(\"Shape:\", df.shape)\n        print(\"Columns:\", df.columns.tolist())\n        print(\"First few rows:\\n\", df.head())\n        \n        # Create temporary file\n        with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', newline='', delete=False, suffix='.csv') as tmp_file:\n            # Write DataFrame to CSV without index\n            df.to_csv(tmp_file.name, index=False, encoding='utf-8')\n            \n            # Debug: Verify CSV content\n            print(\"\\n=== CSV File Content ===\")\n            with open(tmp_file.name, 'r', encoding='utf-8') as f:\n                csv_content = f.read()\n                print(csv_content)\n            print(\"CSV file size:\", os.path.getsize(tmp_file.name), \"bytes\")\n            \n            # Prepare API request\n            url = \"https://us.engagingnetworks.app/ea-dataservice/import.service\"\n            current_time = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S\")\n            \n            data = {\n                'token': api_token,\n                'name': f'Import from Snowflake {current_time}',\n                'formatName': 'classy_to_EN_API'\n            }\n            \n            # Send request using base filename\n            with open(tmp_file.name, 'rb') as f:\n                files = {'file': (base_file_name, f)}  # Use base filename here\n                logger.info(\"Sending API request...\")\n                response = requests.post(url, data=data, files=files)\n                logger.info(f\"Response status code: {response.status_code}\")\n                logger.info(f\"Response content: {response.text}\")\n            \n            # Clean up\n            os.unlink(tmp_file.name)\n            \n            # Check for error in response\n            if \"Error\" in response.text or \"error\" in response.text.lower():\n                raise requests.exceptions.RequestException(f\"API returned error: {response.text}\")\n            \n            return {\n                \"success\": True,\n                \"response\": response\n            }\n            \n    except Exception as e:\n        error_message = str(e)\n        if 'response' in locals():\n            error_message += f\"\\nAPI Response: {response.text}\"\n        return {\n            \"success\": False,\n            \"error\": error_message,\n            \"response\": response if 'response' in locals() else None\n        }\n\ndef write_to_table(session, df):\n    \"\"\"Write data to Snowflake table with timestamp\"\"\"\n    try:\n        # Create new DataFrame with correct column order and types\n        current_time = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n        \n        # Create new DataFrame with timestamp\n        new_df = pd.DataFrame({\n            'INSERTED_AT': [current_time] * len(df),\n            'EMAIL_ADDRESS': df['EMAIL_ADDRESS'],\n            'CLASSY_WALK_2024': df['CLASSY_WALK_2024']\n        })\n        \n        # Create Snowpark DataFrame with explicit schema\n        snowpark_df = session.create_dataframe(\n            new_df,\n            schema=[\"INSERTED_AT\", \"EMAIL_ADDRESS\", \"CLASSY_WALK_2024\"]\n        )\n        \n        # Write to table\n        snowpark_df.write.mode(\"append\").save_as_table(\"CLASSYDATA.EN_API.EN_PUSHED_FUNDRAISERS_WALK2024\")\n        \n        return True\n    except Exception as e:\n        logger.error(f\"Error writing to table: {str(e)}\")\n        raise\n\ndef main():\n    \"\"\"Main execution flow\"\"\"\n    session = get_active_session()\n    \n    try:\n        # Get API token\n        api_token = get_api_token(session)\n        logger.info(\"Retrieved API token\")\n        \n        # Get most recent file\n        file_name = get_most_recent_file(session)\n        logger.info(f\"Selected file: {file_name}\")\n        \n        # Read and validate data\n        df = read_and_validate_data(session, file_name)\n        logger.info(f\"Email addresses validated successfully. {len(df)} records to process\")\n        \n        # Process through API\n        api_result = process_through_api(api_token, df, file_name)\n        \n        if api_result[\"success\"]:\n            # Only write to table if API call was successful\n            write_to_table(session, df)\n            logger.info(\"Data written to table successfully\")\n            \n            return {\n                \"status\": \"success\",\n                \"file_processed\": file_name,\n                \"records_processed\": len(df),\n                \"api_response\": api_result[\"response\"].text if api_result[\"response\"] else \"No response text\"\n            }\n        else:\n            error_info = {\n                \"status\": \"error\",\n                \"error_type\": \"API_Error\",\n                \"error_message\": api_result[\"error\"],\n                \"file_attempted\": file_name,\n                \"timestamp\": datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n            }\n            logger.error(f\"API Processing failed: {error_info}\")\n            return error_info\n            \n    except Exception as e:\n        # Handle non-API errors\n        error_info = {\n            \"status\": \"error\",\n            \"error_type\": type(e).__name__,\n            \"error_message\": str(e),\n            \"timestamp\": datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S\")\n        }\n        logger.error(f\"Processing failed: {error_info}\")\n        return error_info\n\n# Execute main function\nif __name__ == \"__main__\":\n    result = main()\n    print(result)",
   "execution_count": null
  }
 ]
}